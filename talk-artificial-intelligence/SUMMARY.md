Hi everyone,

First of all I'll introduce myself. I'm Simone and I'm a software developer I worked mainly with web technologies, making websites.

ARTIFICIAL INTELLIGENCE
=======================

Today I want to talk about artificial intelligence, or AI.
So I'll start by saying this is not going to be a technical talk; not at all.
There's a lot to say from a technical point of view, however today I will focus
more on ethics. Because also ethics are important, and there's a lot to say there as well.

So.

WHAT IS AI?
===========

The definition of "Artificial Intelligence" is 

The science and engineering of making intelligent machines

especially nowadays we talk about intelligent computer programs. Software. Code, if you prefer. However, we need to be careful with definitions such as this one, because machines are not actually intelligent. They are ("somewhat intelligent" because it's not actual intelligence).

WHAT IS INTELLIGENCE?
=====================

Definition of "Intelligence"
============================

Intelligence is the computational part of the ability to achieve goals in the world.

Obviously intelligence varies a lot between people and animals and machines.
But what I want to say here is, even this definition is a bit vague, right?
It's not immediately clear what intelligence is.

And this is a problem, because people start wondering things, such as:

ETHICAL QUESTIONS
=================

- Should machines have the same rights as humans?
- Should we allow machines to co-exist with people?
- Once machines become more clever than us, will they destroy us?

These are all very good questions. Thing is, nobody knows the answer to these questions. I mean, some people attempted to invent rules for machines to co-exist peacefully.
Raise your hands if you've heard of Isaac (aisac) Asimov's "Three Laws of Robotics".

This is a classic example.

Off the top of my head:

1. A robot may not injure a human being.
2. A robot must obey orders, except where such orders would conflict with the First Law.
3. A robot must protect its own existence, as long as it does not conflict with the First or Second Law.

But what actually happens if/when machines become more intelligent than us?

WHAT IS IT FOR? | REAL-WORLD APPLICATIONS
===============

I could go all day long on this; the field is so broad, right?

Medicine, Biology, Finance, Education...

Before going further 

Before even start trying to answer these questions or defining rules, we need to go back to square one and:
1) Discover "intelligence"
2) Are machines ever going to become sentient?

Personally I think so, I think we could get there.

SINGULARITY
===========

The whole point of this talk is, in order to succeed with artificial intelligence,
we need to first discover/define what intelligence means.


THANK YOU!
=========

So that's me! I hope you guys enjoyed the presentation.

Any questions?
